# âœ¨ Previsione Prezzo Case ğŸ¡

Questo progetto Ã¨ una pipeline di Machine Learning end-to-end per prevedere il prezzo delle case ğŸ  basandosi su un dataset pubblico. Il nostro viaggio include la preparazione accurata dei dati, con un focus speciale sulla **gestione della multicollinearitÃ ** ğŸ“ˆ tra le feature utilizzando un metodo iterativo basato sul Variance Inflation Factor (VIF) ğŸ”. Alla fine, confronteremo le performance di tre popolari modelli di regressione lineare: Regressione Lineare standard, Ridge e Lasso ğŸ“Š.

## ğŸ“‚ Dataset

Il cuore del nostro progetto Ã¨ il dataset `house_data.csv` (o `kc_house_data.csv`). Contiene una ricchezza di informazioni sulle proprietÃ  immobiliari per aiutarci a svelare i segreti dei prezzi delle case!

## âœ… Obiettivi del Progetto

Ecco cosa ci prefiggiamo di fare:

* ğŸ” Caricare ed esplorare i dati per capire di cosa si tratta.
* âœ¨ Pulire i dati, dicendo addio ai duplicati ğŸ‘‹.
* ğŸ“Š Analizzare la correlazione tra le feature con una bella heatmap ğŸ”¥.
* ğŸ”§ Affrontare la multicollinearitÃ : identificare e mitigare le feature problematiche usando un processo di rimozione iterativa basato sul VIF ğŸ”.
    * ğŸ›¡ï¸ **Protezione Speciale:** Alcune feature chiave (come `bathrooms`, `bedrooms`, `floors`) sono protette e non verranno rimosse dal processo VIF, anche se mostrano alta collinearitÃ .
* ğŸ“ Standardizzare le feature per prepararle al meglio per i modelli regolarizzati.
* âœ‚ï¸ Dividere i dati in set di training e test per un addestramento e una valutazione onesti.
* ğŸ§  Addestrare i nostri tre modelli di regressione: Regressione Lineare, Ridge e Lasso.
* ğŸ“ˆ Valutare le performance di ogni modello con metriche di regressione appropriate (R2 Score, MSE, RMSE, MAE).

## ğŸ“ Struttura del Progetto (Esempio)

Per mantenere tutto ordinato ğŸ§¹, il codice Ã¨ suddiviso in file con responsabilitÃ  specifiche:

* ğŸ“„ `main_script.py` (o `run.py`): La mente ğŸ§  dietro l'operazione. Carica i dati, chiama le funzioni di pre-elaborazione e infine addestra/valuta i modelli.
* ğŸ“„ `preprocess.py`: Il pulitore âœ¨ e selezionatore VIF ğŸ”. Contiene la funzione `preprocess(df)` per la pulizia iniziale e la gestione iterativa del VIF.
* ğŸ“„ `features.py`: Lo standardizzatore ğŸ“ e divisore âœ‚ï¸. Contiene la funzione `feature(X_selected, y)` per lo scaling e lo split train/test sui dati giÃ  filtrati.

## ğŸ Requisiti

Per far girare questo progetto sul tuo PC ğŸ’», assicurati di avere installato:

* ğŸ“¦ `pandas`
* ğŸ“¦ `numpy`
* ğŸ“¦ `matplotlib`
* ğŸ“¦ `seaborn`
* ğŸ“¦ `scikit-learn`
* ğŸ“¦ `statsmodels`

Il modo piÃ¹ semplice per installarli Ã¨ via pip in un ambiente virtuale:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn statsmodels
```
Se hai un file requirements.txt, puoi semplicemente usare:
Bash
```
pip install -r requirements.txt
```
â–¶ï¸ Come Eseguire lo Script

Segui questi semplici passi:

  Clona (o scarica) questo repository sul tuo computer.

  âš ï¸ Assicurati che il file del dataset (house_data.csv o kc_house_data.csv) si trovi nella stessa cartella degli script Python, oppure aggiorna il percorso nel codice.

  Apri il terminale o prompt dei comandi nella directory del progetto.

  Esegui lo script principale:
    Bash
```
    python main_script.py
```
Osserva il terminale per vedere i passaggi di pre-elaborazione e i risultati dei modelli! âœ¨
ğŸ”§ Metodologia di Pre-elaborazione Dati

Il processo Ã¨ stato attentamente pensato ğŸ¤”:

  Caricamento & Pulizia: I dati vengono caricati e i duplicati rimossi âœ….
  Split Iniziale X/y: Separiamo le feature dal prezzo target ğŸ¯, rimuovendo colonne non utili.
  Analisi Correlazione: Creiamo una matrice di correlazione visuale (heatmap ğŸ”¥) per capire le relazioni tra le feature numeriche.
  Rimozione Iterativa VIF: Usiamo un loop per identificare e rimuovere le feature con VIF > soglia (default 10) ğŸ”. Le feature protette ('bathrooms', 'bedrooms', 'floors') vengono saltate in questo processo ğŸ›¡ï¸, permettendo al ciclo di continuare a valutare le altre feature.
  Standardizzazione: Le feature selezionate vengono standardizzate (ridimensionate con media 0 e deviazione standard 1) ğŸ“, cruciale per Ridge e Lasso.
  Split Train/Test: I dati standardizzati vengono divisi in set di training e test (80/20) âœ‚ï¸.

ğŸ“Š Valutazione dei Modelli

Ogni modello viene addestrato sul set di training standardizzato e valutato sul set di test utilizzando le metriche fondamentali per la regressione âœ…:

  R2 Score (quanto del prezzo Ã¨ spiegato dal modello)
  Mean Squared Error (MSE)
  Root Mean Squared Error (RMSE - errore tipico nella stessa unitÃ  del prezzo)
  Mean Absolute Error (MAE)

Questi numeri ci dicono quanto bene ogni modello riesce a prevedere i prezzi sul set di dati non visto.
ğŸ“ˆ Risultati e Visualizzazioni (Opzionale)

Lo script stamperÃ  le metriche di valutazione per ogni modello. Per un'analisi visiva piÃ¹ approfondita ğŸ–¼ï¸, potresti aggiungere plot come:

  Uno scatter plot dei prezzi reali vs. i prezzi predetti (ideale: punti su una linea diagonale perfetta).
  Un plot dei residui per controllare l'errore del modello.
